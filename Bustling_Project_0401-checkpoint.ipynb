{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import ceil, floor\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import shapely\n",
    "\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, Polygon, MultiPolygon\n",
    "from geoalchemy2 import Geometry, WKTElement\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sqlalchemy import create_engine, text\n",
    "import psycopg2\n",
    "import psycopg2.extras\n",
    "import json\n",
    "import os\n",
    "\n",
    "import seaborn as sns\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Database Connection Utilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credentials = \"Credentials.json\"\n",
    "\n",
    "def pgconnect(credential_filepath, db_schema=\"public\"):\n",
    "    with open(credential_filepath) as f:\n",
    "        db_conn_dict = json.load(f)\n",
    "        host       = db_conn_dict['host']\n",
    "        db_user    = db_conn_dict['user']\n",
    "        db_pw      = db_conn_dict['password']\n",
    "        default_db = db_conn_dict['user']\n",
    "        port       = db_conn_dict['port']\n",
    "        try:\n",
    "            db = create_engine(f'postgresql+psycopg2://{db_user}:{db_pw}@{host}:{port}/{default_db}', echo=False)\n",
    "            conn = db.connect()\n",
    "            print('Connected successfully.')\n",
    "        except Exception as e:\n",
    "            print(\"Unable to connect to the database.\")\n",
    "            print(e)\n",
    "            db, conn = None, None\n",
    "        return db,conn\n",
    "\n",
    "def query_funct(conn, sqlcmd, args=None, df=True):\n",
    "    result = pd.DataFrame() if df else None\n",
    "    try:\n",
    "        if df:\n",
    "            result = pd.read_sql_query(sqlcmd, conn, params=args)\n",
    "        else:\n",
    "            result = conn.execute(text(sqlcmd), args).fetchall()\n",
    "            result = result[0] if len(result) == 1 else result\n",
    "    except Exception as e:\n",
    "        print(\"Error encountered: \", e, sep='\\n')\n",
    "    return result\n",
    "\n",
    "db, conn = pgconnect(credentials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following python script drop table before everything has been run to ensure no duplicate value been append to the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all existing tables if they already exist to prevent dupilicate value\n",
    "remove_tables = '''\n",
    "DROP TABLE IF EXISTS modified_polling CASCADE;\n",
    "DROP TABLE IF EXISTS sa2_greater_sydney CASCADE;\n",
    "DROP TABLE IF EXISTS sydney_businesses CASCADE;\n",
    "DROP TABLE IF EXISTS sydney_income;\n",
    "DROP TABLE IF EXISTS sydney_population;\n",
    "DROP TABLE IF EXISTS combined_school;\n",
    "DROP TABLE IF EXISTS stops;\n",
    "DROP TABLE IF EXISTS all_facilities_clean;\n",
    "DROP TABLE IF EXISTS housing;\n",
    "DROP TABLE IF EXISTS healthcare_facilities CASCADE;\n",
    "DROP TABLE IF EXISTS education_facilities CASCADE;\n",
    "'''\n",
    "\n",
    "conn.execute(text(remove_tables))\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# CSV FILEs Clean up\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following codes load 'business', 'income' and 'population' data file, and check the null value for each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "business_df = pd.read_csv('data/Businesses.csv')\n",
    "null_percentage = business_df.isnull().mean() * 100\n",
    "\n",
    "income_df = pd.read_csv('data/Income.csv')\n",
    "null_percentage = income_df.isnull().mean() * 100\n",
    "\n",
    "sydney_population_df = pd.read_csv('data/Population.csv')\n",
    "null_percentage = sydney_population_df.isnull().mean() * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "has_null = business_df.isnull().values.any() and income_df.isnull().values.any() and sydney_population_df.isnull().values.any() \n",
    "# print(\"Are there any null values in the csv files?\", has_null)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  PoolingPlaces2019.csv -> geo data \n",
    "\n",
    "has street address is broken down in \"3 Premises\" -> this refers to the street name, followed by premises suburb , state and post code; \n",
    "\n",
    "for simplcity we will merge \"premises_address_1\tpremises_address_2\tpremises_address_3\" in to stree_address "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polls = pd.read_csv('data/PollingPlaces2019.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Combine Street Address Components    \n",
    "\n",
    "combine premises_address_1, premises_address_2, and premises_address_3 into a street_address. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_street_columns(dataframe):\n",
    "    df_copy = dataframe.copy()\n",
    "    \n",
    "    # Create the combined address column but do not immediately add it to DataFrame\n",
    "    combined_address = df_copy[['premises_address_1', 'premises_address_2', 'premises_address_3']].fillna('').agg(' '.join, axis=1).str.strip()\n",
    "    \n",
    "    # Insert the new 'full_address' column before 'premises_address_1'\n",
    "    position = df_copy.columns.get_loc('premises_address_1')\n",
    "    df_copy.insert(position, 'street_address', combined_address)\n",
    "    \n",
    "    # Drop the original address columns\n",
    "    df_copy = df_copy.drop(['premises_address_1', 'premises_address_2', 'premises_address_3'], axis=1)\n",
    "    \n",
    "    return df_copy\n",
    "\n",
    "def combine_all_address(dataframe):\n",
    "    df_copy = dataframe.copy()\n",
    "    \n",
    "    # Explicitly convert each column to string and handle NaNs\n",
    "    address_components = ['street_address', 'premises_suburb', 'premises_post_code']\n",
    "    df_copy[address_components] = df_copy[address_components].fillna('').astype(str)\n",
    "    \n",
    "    # Create the combined address column from multiple components\n",
    "    # Only create 'full_address' if there are meaningful contents in the address components\n",
    "    def create_full_address(row):\n",
    "        if row['street_address'].strip() and row['premises_suburb'].strip() and row['premises_post_code'].strip():\n",
    "            return f\"{row['street_address']}, {row['premises_suburb']}, {row['premises_post_code']}\"\n",
    "        else:\n",
    "            return None\n",
    "    \n",
    "    df_copy['full_address'] = df_copy.apply(create_full_address, axis=1)\n",
    "    \n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Combine All Address Components into Full Address\n",
    "\n",
    "Modify the combine_all_address function to include a condition that checks if the components are not just empty strings before concatenating them into full_address."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to the DataFrame\n",
    "modified_polling = combine_street_columns(polls)\n",
    "modified_polling = combine_all_address(modified_polling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Condition to find entries missing latitude or longitude\n",
    "missing_geo_condition = modified_polling['full_address'].notnull() & (modified_polling['latitude'].isnull() | modified_polling['longitude'].isnull())\n",
    "\n",
    "# Create a separate DataFrame for these entries\n",
    "missing_geo_df = modified_polling[missing_geo_condition].copy()\n",
    "\n",
    "print(\"Entries needing geocoding:\", len(missing_geo_df))\n",
    "print(missing_geo_df[['full_address', 'latitude', 'longitude']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find duplicates based on both 'full_address' and 'polling_place_id'\n",
    "duplicates = modified_polling[modified_polling.duplicated(subset=['full_address', 'polling_place_id'], keep=False)]\n",
    "\n",
    "# Display duplicates if found\n",
    "if not duplicates.empty:\n",
    "    print(\"Duplicate entries based on address and place ID found:\")\n",
    "    print(duplicates[['polling_place_id', 'full_address', 'latitude', 'longitude']])\n",
    "else:\n",
    "    print(\"No duplicate entries based on address and place ID found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from geoalchemy2 import WKTElement\n",
    "from shapely.geometry import Polygon, MultiPolygon, Point\n",
    "\n",
    "# Convert to GeoDataFrame\n",
    "def convert_to_geodataframe(dataframe):\n",
    "    # Make sure latitude and longitude columns exist\n",
    "    assert 'latitude' in dataframe.columns, \"Missing 'latitude' column\"\n",
    "    assert 'longitude' in dataframe.columns, \"Missing 'longitude' column\"\n",
    "    \n",
    "    # Create a GeoDataFrame with geometry from latitude and longitude\n",
    "    gdf = gpd.GeoDataFrame(dataframe, geometry=gpd.points_from_xy(dataframe['longitude'], dataframe['latitude'], crs='EPSG:4326'))\n",
    "    return gdf\n",
    "\n",
    "modified_polling = convert_to_geodataframe(modified_polling)\n",
    "\n",
    "def create_wkt_element(geom, srid = 4326):\n",
    "    if geom.geom_type == 'Polygon':\n",
    "        geom = MultiPolygon([geom])\n",
    "    return WKTElement(geom.wkt, srid=srid)\n",
    "\n",
    "modified_polling['the_geom'] = modified_polling['the_geom'].fillna(Point())\n",
    "\n",
    "# Apply the function to each geometry object in the dataframe\n",
    "modified_polling['the_geom'] = modified_polling['geometry'].apply(lambda x: create_wkt_element(x))\n",
    "\n",
    "# Drop the `geometry` column\n",
    "modified_polling = modified_polling.drop(columns='geometry')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the data into database using to_sql command and create the Spatial Index which allows for efficient access to spatial data, such as geometries representing locations and shapes on the earth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    srid = 4326\n",
    "    modified_polling.to_sql(\n",
    "        \"modified_polling\",\n",
    "        conn,\n",
    "        if_exists='replace',\n",
    "        index=False,\n",
    "        dtype={'the_geom': Geometry('POINT', srid)}\n",
    "    )\n",
    "    \n",
    "    spatial_index_modified_polling = '''\n",
    "    CREATE INDEX idx_modified_polling_geom\n",
    "    ON modified_polling\n",
    "    USING GIST (the_geom);\n",
    "    '''\n",
    "\n",
    "    # Create a spatial index\n",
    "    conn.execute(text(spatial_index_modified_polling))\n",
    "    conn.commit()\n",
    "except Exception as e:\n",
    "    # Roll back the transaction if an error occurs\n",
    "    print(f\"Error occurred: {e}\")\n",
    "    conn.rollback()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SCHOOLS Primary & Secondary & Future .shp file\n",
    "### The following python script uses geopanda to read the shape file and do the necessary data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# primary school data\n",
    "primary_school = gpd.read_file(\"data/schools/catchments_primary.shp\")\n",
    "primary_school = primary_school.rename(columns={'geometry': 'geom'})\n",
    "primary_school.columns = primary_school.columns.str.lower()\n",
    "\n",
    "# secondary_school data\n",
    "secondary_school = gpd.read_file(\"data/schools/catchments_secondary.shp\")\n",
    "secondary_school = secondary_school.rename(columns={'geometry': 'geom'})\n",
    "secondary_school.columns = secondary_school.columns.str.lower()\n",
    "\n",
    "# future_school data\n",
    "future_school = gpd.read_file(\"data/schools/catchments_future.shp\")\n",
    "future_school = future_school.rename(columns={'geometry': 'geom'})\n",
    "future_school.columns = future_school.columns.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_column(df, column, before_col):\n",
    "    cols = list(df.columns)\n",
    "    \n",
    "    # Remove the column to move\n",
    "    cols.remove(column)\n",
    "    \n",
    "    # Find the index of the target column\n",
    "    before_idx = cols.index(before_col)\n",
    "    \n",
    "    # Insert the column at the specified position\n",
    "    cols.insert(before_idx, column)\n",
    "    \n",
    "    return df[cols]\n",
    "\n",
    "missing_columns = set(primary_school.columns) - set(future_school.columns)\n",
    "for col in missing_columns:\n",
    "    future_school[col] = None\n",
    "\n",
    "future_school = move_column(future_school, 'priority', 'geom')\n",
    "year_columns = ['kindergart', 'year1', 'year2', 'year3', 'year4', 'year5',\n",
    "                'year6', 'year7', 'year8', 'year9', 'year10', 'year11', 'year12']\n",
    "\n",
    "# Interpret `0` as 'N' and any year (e.g., `2024`) as 'Y'\n",
    "for col in year_columns:\n",
    "    future_school[col] = future_school[col].apply(lambda x: 'N' if x == 0 else 'Y')\n",
    "\n",
    "merged_schools = pd.concat([primary_school, secondary_school, future_school], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "srid = 4326\n",
    "def create_wkt_element(geom, srid):\n",
    "    if geom is None:\n",
    "        return None\n",
    "    if geom.geom_type == 'Polygon':\n",
    "        geom = MultiPolygon([geom])\n",
    "    return WKTElement(geom.wkt, srid)\n",
    "\n",
    "merged_schools_cp = merged_schools.copy()  # creating a copy of the original for later\n",
    "merged_schools['geom'] = merged_schools['geom'].apply(lambda x: create_wkt_element(geom=x, srid=srid))  # applying the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_table_combined_school = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS combined_school (\n",
    "    use_id serial,\n",
    "    catch_type VARCHAR(255),\n",
    "    use_desc VARCHAR(255),\n",
    "    add_date DATE,\n",
    "    kindergart CHAR(1),\n",
    "    year1 CHAR(1),\n",
    "    year2 CHAR(1),\n",
    "    year3 CHAR(1),\n",
    "    year4 CHAR(1),\n",
    "    year5 CHAR(1),\n",
    "    year6 CHAR(1),\n",
    "    year7 CHAR(1),\n",
    "    year8 CHAR(1),\n",
    "    year9 CHAR(1),\n",
    "    year10 CHAR(1),\n",
    "    year11 CHAR(1),\n",
    "    year12 CHAR(1),\n",
    "    priority VARCHAR(50),\n",
    "    geom GEOMETRY(multipolygon, 4326)\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "conn.execute(text(create_table_combined_school))\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_schools.to_sql(\n",
    "    'combined_school',\n",
    "    conn,\n",
    "    if_exists='append',\n",
    "    index=False,\n",
    "    dtype={'geom': Geometry('MULTIPOLYGON', srid)}\n",
    ")\n",
    "\n",
    "spatial_index_merged_school = '''\n",
    "CREATE INDEX idx_mergd_school_geom\n",
    "ON combined_school\n",
    "USING GIST (geom);\n",
    "'''\n",
    "\n",
    "# Create a spatial index\n",
    "conn.execute(text(spatial_index_merged_school))\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SA2-GDA shape file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gda = gpd.read_file(\"data/SA2_2021_AUST_SHP_GDA2020/SA2_2021_AUST_GDA2020.shp\")\n",
    "gdaog = gda.copy()  # creating a copy of the original for later\n",
    "\n",
    "# considering the original dataset isn't in epsg 4326 form, so we have to convert it first\n",
    "gda_4326 = gda.to_crs(epsg=4326)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "srid = 4326\n",
    "def create_wkt_element(geom, srid):\n",
    "    if geom is None:\n",
    "        return None\n",
    "    if geom.geom_type == 'Polygon':\n",
    "        geom = MultiPolygon([geom])\n",
    "    return WKTElement(geom.wkt, srid)\n",
    "\n",
    "gdaog = gda_4326.copy()  # creating a copy of the original for later\n",
    "\n",
    "greater_sydney_gcc_code = '1GSYD'\n",
    "gda_sydney = gda_4326[gda_4326['GCC_CODE21'] == greater_sydney_gcc_code].copy()\n",
    "\n",
    "gda_sydney.loc[:, 'the_geom'] = gda_sydney['geometry'].apply(lambda x: create_wkt_element(geom=x, srid=srid))\n",
    "\n",
    "gda_sydney = gda_sydney.drop(columns='geometry')\n",
    "\n",
    "gda_sydney.columns = [\n",
    "    'sa2_code21', 'sa2_name21', 'chg_flag21', 'chg_lbl21',\n",
    "    'sa3_code21', 'sa3_name21', 'sa4_code21', 'sa4_name21',\n",
    "    'gcc_code21', 'gcc_name21', 'ste_code21', 'ste_name21',\n",
    "    'aus_code21', 'aus_name21', 'areasqkm21', 'loci_uri21', 'the_geom'\n",
    "]\n",
    "\n",
    "gda_sydney['sa2_code21'] = gda_sydney['sa2_code21'].astype(int, errors='ignore')\n",
    "\n",
    "filtered_sa2_codes = gda_sydney['sa2_code21'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "create_sa2_table = '''\n",
    "CREATE TABLE IF NOT EXISTS sa2_greater_sydney (\n",
    "    sa2_code21 INT NOT NULL,\n",
    "    sa2_name21 VARCHAR(100),\n",
    "    chg_flag21 VARCHAR(1),\n",
    "    chg_lbl21 VARCHAR(50),\n",
    "    sa3_code21 VARCHAR(5),\n",
    "    sa3_name21 VARCHAR(100),\n",
    "    sa4_code21 VARCHAR(3),\n",
    "    sa4_name21 VARCHAR(100),\n",
    "    gcc_code21 VARCHAR(5),\n",
    "    gcc_name21 VARCHAR(100),\n",
    "    ste_code21 VARCHAR(2),\n",
    "    ste_name21 VARCHAR(100),\n",
    "    aus_code21 VARCHAR(3),\n",
    "    aus_name21 VARCHAR(100),\n",
    "    areasqkm21 FLOAT,\n",
    "    loci_uri21 TEXT,\n",
    "    the_geom GEOMETRY(MULTIPOLYGON, 4326),\n",
    "    PRIMARY KEY (sa2_code21)\n",
    ");\n",
    "'''\n",
    "conn.execute(text(create_sa2_table))\n",
    "\n",
    "try:\n",
    "    srid = 4326\n",
    "    gda_sydney.to_sql(\n",
    "        'sa2_greater_sydney',\n",
    "        conn,\n",
    "        if_exists='append',\n",
    "        index=False,\n",
    "        dtype={'the_geom': Geometry('MULTIPOLYGON', srid)}\n",
    "    )\n",
    "    \n",
    "    spatial_index_sa2_sydney = '''\n",
    "    CREATE INDEX idx_sa2_geom\n",
    "    ON sa2_greater_sydney\n",
    "    USING GIST (the_geom);\n",
    "    '''\n",
    "\n",
    "    # Create a spatial index\n",
    "    conn.execute(text(spatial_index_sa2_sydney))\n",
    "    conn.commit()\n",
    "except Exception as e:\n",
    "    # Roll back the transaction if an error occurs\n",
    "    print(f\"Error occurred: {e}\")\n",
    "    conn.rollback()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stops.txt to Geo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from geoalchemy2 import WKTElement\n",
    "from shapely.geometry import Polygon, MultiPolygon, Point\n",
    "\n",
    "\n",
    "stops_df = pd.read_csv(\"data/stops.txt\")\n",
    "stops_df_cp = stops_df.copy()  # creating a copy of the original for later\n",
    "\n",
    "stops_df['stop_code'] = stops_df['stop_code'].fillna(stops_df['stop_id']).astype(str)\n",
    "\n",
    "def convert_to_geodataframe_for_stops(dataframe):\n",
    "    # Make sure latitude and longitude columns exist\n",
    "    assert 'stop_lat' in dataframe.columns, \"Missing 'stop_lat' column\"\n",
    "    assert 'stop_lon' in dataframe.columns, \"Missing 'stop_lon' column\"\n",
    "    \n",
    "    # Create a GeoDataFrame with geometry from latitude and longitude\n",
    "    gdf = gpd.GeoDataFrame(\n",
    "        dataframe,\n",
    "        geometry=gpd.points_from_xy(dataframe['stop_lon'], dataframe['stop_lat'], crs='EPSG:4326')\n",
    "    )\n",
    "    return gdf\n",
    "\n",
    "stops_gdf = convert_to_geodataframe_for_stops(stops_df)\n",
    "\n",
    "# Apply the function to each geometry object in the dataframe\n",
    "stops_gdf['the_geom'] = stops_gdf['geometry'].apply(lambda x: create_wkt_element(x, srid = 4326))\n",
    "\n",
    "# Drop the `geometry` column\n",
    "stops_gdf = stops_gdf.drop(columns='geometry')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    srid = 4326\n",
    "    stops_gdf.to_sql(\n",
    "        \"stops\",\n",
    "        conn,\n",
    "        if_exists='append',\n",
    "        index=False,\n",
    "        dtype={'the_geom': Geometry('POINT', srid)}\n",
    "    )\n",
    "    \n",
    "    spatial_index_stops = '''\n",
    "    CREATE INDEX idx_stops_geom\n",
    "    ON stops\n",
    "    USING GIST (the_geom);\n",
    "    '''\n",
    "\n",
    "    # Create a spatial index\n",
    "    conn.execute(text(spatial_index_stops))\n",
    "    conn.commit()\n",
    "except Exception as e:\n",
    "    # Roll back the transaction if an error occurs\n",
    "    print(f\"Error occurred: {e}\")\n",
    "    conn.rollback()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter csv data to only consider great sydney regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filtered_income_df = income_df[income_df['sa2_code21'].isin(filtered_sa2_codes)]\n",
    "filtered_income_df.columns = filtered_income_df.columns.str.lower()\n",
    "filtered_income_df.loc[:, 'median_income'] = pd.to_numeric(filtered_income_df['median_income'], errors='coerce')\n",
    "filtered_income_df.loc[:, 'median_age'] = pd.to_numeric(filtered_income_df['median_age'], errors='coerce')\n",
    "filtered_income_df.loc[:, 'mean_income'] = pd.to_numeric(filtered_income_df['mean_income'], errors='coerce')\n",
    "\n",
    "\n",
    "filtered_business_df = business_df[business_df['sa2_code'].isin(filtered_sa2_codes)]\n",
    "filtered_business_df.columns = filtered_business_df.columns.str.lower()\n",
    "\n",
    "filtered_population_df = sydney_population_df[sydney_population_df['sa2_code'].isin(filtered_sa2_codes)]\n",
    "filtered_population_df.columns = filtered_population_df.columns.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_table_income = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS sydney_income (\n",
    "    sa2_code21 INT REFERENCES sa2_greater_sydney(sa2_code21),\n",
    "    sa2_name VARCHAR(255),\n",
    "    earners VARCHAR(255),\n",
    "    median_age NUMERIC,\n",
    "    median_income NUMERIC,\n",
    "    mean_income NUMERIC\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "create_table_business = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS sydney_businesses (\n",
    "    industry_code VARCHAR(255),\n",
    "    industry_name VARCHAR(255),\n",
    "    sa2_code INT REFERENCES sa2_greater_sydney(sa2_code21),\n",
    "    sa2_name VARCHAR(255),\n",
    "    \"0_to_50k_businesses\" INT,\n",
    "    \"50k_to_200k_businesses\" INT,\n",
    "    \"200k_to_2m_businesses\" INT,\n",
    "    \"2m_to_5m_businesses\" INT,\n",
    "    \"5m_to_10m_businesses\" INT,\n",
    "    \"10m_or_more_businesses\" INT,\n",
    "    total_businesses INT\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "create_table_population = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS sydney_population (\n",
    "    sa2_code INT REFERENCES sa2_greater_sydney(sa2_code21),\n",
    "    sa2_name VARCHAR(255),\n",
    "    \"0-4_people\" INT,\n",
    "    \"5-9_people\" INT,\n",
    "    \"10-14_people\" INT,\n",
    "    \"15-19_people\" INT,\n",
    "    \"20-24_people\" INT,\n",
    "    \"25-29_people\" INT,\n",
    "    \"30-34_people\" INT,\n",
    "    \"35-39_people\" INT,\n",
    "    \"40-44_people\" INT,\n",
    "    \"45-49_people\" INT,\n",
    "    \"50-54_people\" INT,\n",
    "    \"55-59_people\" INT,\n",
    "    \"60-64_people\" INT,\n",
    "    \"65-69_people\" INT,\n",
    "    \"70-74_people\" INT,\n",
    "    \"75-79_people\" INT,\n",
    "    \"80-84_people\" INT,\n",
    "    \"85-and-over_people\" INT,\n",
    "    total_people INT\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "conn.execute(text(create_table_income))\n",
    "conn.execute(text(create_table_business))\n",
    "conn.execute(text(create_table_population))\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data into the database\n",
    "filtered_business_df.to_sql(\n",
    "    'sydney_businesses',\n",
    "    conn,\n",
    "    if_exists='append',\n",
    "    index=False\n",
    ")\n",
    "\n",
    "filtered_income_df.to_sql(\n",
    "    'sydney_income',\n",
    "    conn,\n",
    "    if_exists='append',\n",
    "    index=False\n",
    ")\n",
    "\n",
    "filtered_population_df.to_sql(\n",
    "    'sydney_population',\n",
    "    conn,\n",
    "    if_exists='append',\n",
    "    index=False\n",
    ")\n",
    "\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out the sa2 regeion with a population less than 100\n",
    "join_population_sa2 = '''\n",
    "CREATE OR REPLACE VIEW filtered_sydney_population AS\n",
    "SELECT \n",
    "    sp.*,\n",
    "    ss.the_geom\n",
    "FROM \n",
    "    sydney_population sp\n",
    "JOIN \n",
    "    sa2_greater_sydney ss ON sp.sa2_code = ss.sa2_code21\n",
    "WHERE \n",
    "    sp.total_people >= 100;\n",
    "'''\n",
    "\n",
    "conn.execute(text(join_population_sa2))\n",
    "conn.commit()\n",
    "\n",
    "query_funct(conn, text(\"select * from filtered_sydney_population\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Z Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determining which Bussiness Industry to pick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "SELECT industry_name, COUNT(*) AS frequency, AVG(businesses_per_1000_people) AS avg_density\n",
    "FROM (\n",
    "    SELECT sa2_name, industry_name, businesses_per_1000_people\n",
    "    FROM (\n",
    "        SELECT\n",
    "            sa2_name21 AS sa2_name,\n",
    "            industry_name,\n",
    "            SUM(total_businesses) AS total_businesses,\n",
    "            SUM(total_people) AS total_people,\n",
    "            (SUM(total_businesses) * 1000.0) / SUM(total_people) AS businesses_per_1000_people,\n",
    "            RANK() OVER (ORDER BY (SUM(total_businesses) * 1000.0) / SUM(total_people) DESC) AS rank\n",
    "        FROM public.sydney_businesses b\n",
    "        JOIN public.sa2_greater_sydney sa2 ON sa2.sa2_code21 = b.sa2_code\n",
    "        JOIN public.sydney_population p ON sa2.sa2_code21 = p.sa2_code\n",
    "        WHERE p.total_people >= 100\n",
    "        GROUP BY sa2.sa2_name21, industry_name\n",
    "    ) AS ranked_industries\n",
    "    WHERE rank <= 50\n",
    ") AS top_industries\n",
    "GROUP BY industry_name\n",
    "ORDER BY frequency DESC, avg_density DESC;\n",
    "\"\"\"\n",
    "\n",
    "query_funct(conn, sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequency and Density Analysis Results\n",
    "\n",
    "- **Frequency**: The number of times an industry appears in the top 50 list.\n",
    "- **Average Business Density**: The average number of businesses per 1000 people for each industry among its appearances in the top 50.\n",
    "\n",
    "### Top Industries Based on Data Analysis\n",
    "\n",
    "- **Financial and Insurance Services**: \n",
    "  - **Appearances**: 3\n",
    "  - **Average Business Density**: 464.86\n",
    "  - **Interpretation**: Although it appeared only three times, it had the highest average business density. This suggests a very high concentration of financial businesses in the regions where it appears, indicating significant economic activity.\n",
    "\n",
    "- **Rental, Hiring and Real Estate Services**:\n",
    "  - **Appearances**: 9\n",
    "  - **Average Business Density**: 163.40\n",
    "  - **Interpretation**: This industry appeared nine times with an average density of 163.40, indicating it is widespread and significantly bustling.\n",
    "\n",
    "- **Professional, Scientific and Technical Services**:\n",
    "  - **Appearances**: 13\n",
    "  - **Average Business Density**: 144.20\n",
    "  - **Interpretation**: The most frequent with thirteen appearances, although with a lower density compared to Financial Services. It's broadly active across multiple regions.\n",
    "\n",
    "### Recommendations for Focus Industry\n",
    "\n",
    "- If the goal is to highlight the most **intensely bustling areas**, **Financial and Insurance Services** would be the best focus due to its exceptionally high business density.\n",
    "- If the goal is to reflect **widespread economic activity** across many regions, **Professional, Scientific and Technical Services** stands out due to its frequency and reasonably high business density.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If the objective is to demonstrate an industryâ€™s impact on the bustling nature of SA2 regions comprehensively, Professional, Scientific and Technical Services would be a pragmatic choice due to its presence in a larger number of top regions, suggesting it plays a crucial role in the economic fabric of Greater Sydney."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2 Progress Summary: Computing \"Well-Resourced\" Score for SA2 Regions\n",
    "\n",
    "### Objective\n",
    "Calculate a \"well-resourced\" score for each SA2 region based on multiple metrics including business density, stops, polls, and schools. This is aimed at identifying how well-resourced each neighborhood is.\n",
    "\n",
    "### Current Progress\n",
    "\n",
    "#### Business Metric Calculation\n",
    "- **Industry Focus**: Professional, Scientific, and Technical Services\n",
    "- **Methodology**:\n",
    "  - Extracted data for total businesses and population for SA2 regions from the provided datasets.\n",
    "  - Computed the number of businesses per 1000 people for this industry.\n",
    "  - Calculated the z-score for this metric to standardize across all SA2 regions.\n",
    "\n",
    "#### SQL Query for Business Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "join_business_sa2 = '''\n",
    "CREATE OR REPLACE VIEW filtered_sydney_businesses AS\n",
    "SELECT\n",
    "    sb.*,\n",
    "    fsp.the_geom\n",
    "FROM\n",
    "    sydney_businesses sb\n",
    "JOIN\n",
    "    filtered_sydney_population fsp ON sb.sa2_code = fsp.sa2_code;\n",
    "'''\n",
    "\n",
    "weighted_industry_businesses = '''\n",
    "CREATE OR REPLACE VIEW weighted_industry_businesses AS\n",
    "SELECT\n",
    "    sb.sa2_code,\n",
    "    sb.sa2_name,\n",
    "    sb.industry_name,\n",
    "    SUM(\n",
    "        COALESCE(sb.\"0_to_50k_businesses\", 0) * 1 +\n",
    "        COALESCE(sb.\"50k_to_200k_businesses\", 0) * 2 +\n",
    "        COALESCE(sb.\"200k_to_2m_businesses\", 0) * 3 +\n",
    "        COALESCE(sb.\"2m_to_5m_businesses\", 0) * 4 +\n",
    "        COALESCE(sb.\"5m_to_10m_businesses\", 0) * 5 +\n",
    "        COALESCE(sb.\"10m_or_more_businesses\", 0) * 6\n",
    "    ) AS weighted_num_industry_businesses,\n",
    "    sb.the_geom\n",
    "FROM\n",
    "    filtered_sydney_businesses sb\n",
    "WHERE\n",
    "    sb.industry_name = 'Professional, Scientific and Technical Services'\n",
    "GROUP BY\n",
    "    sb.sa2_code,\n",
    "    sb.sa2_name,\n",
    "    sb.industry_name,\n",
    "    sb.the_geom;\n",
    "'''\n",
    "\n",
    "# Create a view for selected industry business\n",
    "selected_industry_businesses_per_1000 = '''\n",
    "CREATE OR REPLACE VIEW selected_industry_businesses_per_1000 AS\n",
    "SELECT\n",
    "    wi.sa2_code,\n",
    "    wi.sa2_name,\n",
    "    wi.industry_name,\n",
    "    wi.weighted_num_industry_businesses,\n",
    "    fsp.total_people,\n",
    "    (wi.weighted_num_industry_businesses::FLOAT / NULLIF(fsp.total_people, 0)) * 1000 AS businesses_per_1000,\n",
    "    wi.the_geom\n",
    "FROM\n",
    "    weighted_industry_businesses wi\n",
    "JOIN\n",
    "    filtered_sydney_population fsp ON wi.sa2_code = fsp.sa2_code;\n",
    "'''\n",
    "\n",
    "# Compute zscore for business\n",
    "zscore_selected_industry_businesses = '''\n",
    "CREATE OR REPLACE VIEW zscore_selected_industry_businesses AS\n",
    "SELECT\n",
    "    sa2_code,\n",
    "    sa2_name,\n",
    "    industry_name,\n",
    "    weighted_num_industry_businesses,\n",
    "    total_people,\n",
    "    businesses_per_1000,\n",
    "    (businesses_per_1000 - AVG(businesses_per_1000) OVER ()) / NULLIF(STDDEV(businesses_per_1000) OVER (), 0) AS zscore_business,\n",
    "    the_geom\n",
    "FROM\n",
    "    selected_industry_businesses_per_1000;\n",
    "'''\n",
    "\n",
    "conn.execute(text(join_business_sa2))\n",
    "conn.execute(text(weighted_industry_businesses))\n",
    "conn.execute(text(selected_industry_businesses_per_1000))\n",
    "conn.execute(text(zscore_selected_industry_businesses))\n",
    "conn.commit()\n",
    "\n",
    "query_funct(conn, \"select * from zscore_selected_industry_businesses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use ST_Contains to join stops with SA2 regions filtered by population.\n",
    "filtered_sydney_stops = '''\n",
    "CREATE OR REPLACE VIEW filtered_sydney_stops AS\n",
    "SELECT\n",
    "    s.*\n",
    "FROM\n",
    "    stops s\n",
    "JOIN\n",
    "    sa2_greater_sydney sg ON ST_Contains(sg.the_geom, s.the_geom)\n",
    "JOIN\n",
    "    filtered_sydney_population fsp ON sg.sa2_code21 = fsp.sa2_code;\n",
    "'''\n",
    "\n",
    "# uses ST_Contains to assign stops to SA2 regions.\n",
    "stops_per_sa2 = '''\n",
    "CREATE OR REPLACE VIEW stops_per_sa2 AS\n",
    "SELECT\n",
    "    sg.sa2_code21,\n",
    "    sg.sa2_name21,\n",
    "    COUNT(s.stop_id) AS num_stops,\n",
    "    ST_Area(ST_Transform(sg.the_geom, 3857)) / POWER(1000, 2) AS area_sq_km \n",
    "FROM\n",
    "    sa2_greater_sydney sg\n",
    "JOIN\n",
    "    filtered_sydney_stops s ON ST_Contains(sg.the_geom, s.the_geom)\n",
    "GROUP BY\n",
    "    sg.sa2_code21,\n",
    "    sg.the_geom;\n",
    "'''\n",
    "\n",
    "# Calculate the z-score based on the number of stops per SA2 region.\n",
    "zscore_stops = '''\n",
    "CREATE OR REPLACE VIEW zscore_stops AS\n",
    "SELECT\n",
    "    sa2_code21,\n",
    "    sa2_name21,\n",
    "    num_stops,\n",
    "    num_stops / NULLIF(area_sq_km, 0) AS stops_per_sq_km,\n",
    "    (num_stops / NULLIF(area_sq_km, 0) - AVG(num_stops / NULLIF(area_sq_km, 0)) OVER ()) / NULLIF(STDDEV(num_stops / NULLIF(area_sq_km, 0)) OVER (), 0) AS zscore_stops\n",
    "FROM\n",
    "    stops_per_sa2;\n",
    "'''\n",
    "\n",
    "conn.execute(text(filtered_sydney_stops))\n",
    "conn.execute(text(stops_per_sa2))\n",
    "conn.execute(text(zscore_stops))\n",
    "conn.commit()\n",
    "\n",
    "query_funct(conn, \"select * from zscore_stops\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "join_polling_places_sa2 = '''\n",
    "CREATE OR REPLACE VIEW filtered_polling_places AS\n",
    "SELECT\n",
    "    sg.sa2_code21,\n",
    "    p.*\n",
    "FROM\n",
    "    modified_polling p\n",
    "JOIN\n",
    "    sa2_greater_sydney sg ON ST_Contains(sg.the_geom, p.the_geom)\n",
    "JOIN\n",
    "    filtered_sydney_population fsp ON sg.sa2_code21 = fsp.sa2_code;\n",
    "'''\n",
    "\n",
    "conn.execute(text(join_polling_places_sa2))\n",
    "conn.commit()\n",
    "\n",
    "# Calculate the number of polling places per SA2 region\n",
    "polls_per_sa2_view = '''\n",
    "CREATE OR REPLACE VIEW polls_per_sa2 AS\n",
    "SELECT\n",
    "    fsp.sa2_code,\n",
    "    COUNT(p.polling_place_id) AS num_polls\n",
    "FROM\n",
    "    filtered_sydney_population fsp\n",
    "LEFT JOIN\n",
    "    filtered_polling_places p ON fsp.sa2_code = p.sa2_code21\n",
    "GROUP BY\n",
    "    fsp.sa2_code;\n",
    "'''\n",
    "\n",
    "conn.execute(text(polls_per_sa2_view))\n",
    "conn.commit()\n",
    "\n",
    "# Calculate the z-score for polling places\n",
    "zscore_polls_view = '''\n",
    "CREATE OR REPLACE VIEW zscore_polls AS\n",
    "SELECT\n",
    "    sa2_code,\n",
    "    num_polls,\n",
    "    (num_polls - AVG(num_polls) OVER ()) / NULLIF(STDDEV(num_polls) OVER (), 0) AS zscore_polls\n",
    "FROM\n",
    "    polls_per_sa2;\n",
    "'''\n",
    "conn.execute(text(zscore_polls_view))\n",
    "conn.commit()\n",
    "\n",
    "query_funct(conn, \"select * from zscore_polls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "join_population_for_young_people = '''\n",
    "CREATE OR REPLACE VIEW filtered_sydney_young_people AS\n",
    "SELECT\n",
    "    sp.sa2_code,\n",
    "    sp.total_people,\n",
    "    (sp.\"0-4_people\" + sp.\"5-9_people\" + sp.\"10-14_people\" + sp.\"15-19_people\") AS young_people\n",
    "FROM\n",
    "    sydney_population sp\n",
    "JOIN\n",
    "    sa2_greater_sydney ss ON sp.sa2_code = ss.sa2_code21\n",
    "WHERE\n",
    "    sp.total_people >= 100;\n",
    "'''\n",
    "\n",
    "schools_per_sa2_view = '''\n",
    "CREATE OR REPLACE VIEW schools_per_sa2 AS\n",
    "SELECT\n",
    "    sg.sa2_code21 AS sa2_code,\n",
    "    COUNT(cs.use_id) AS num_schools,\n",
    "    ST_Area(ST_Transform(sg.the_geom, 3857)) / 1000000 AS area_sq_km\n",
    "FROM\n",
    "    sa2_greater_sydney sg\n",
    "JOIN\n",
    "    combined_school cs ON ST_Intersects(sg.the_geom, cs.geom)\n",
    "GROUP BY\n",
    "    sg.sa2_code21,\n",
    "    sg.the_geom;\n",
    "'''\n",
    "\n",
    "schools_per_1000 = '''\n",
    "CREATE OR REPLACE VIEW schools_per_1000 AS\n",
    "SELECT\n",
    "    fsp.sa2_code,\n",
    "    num_schools,\n",
    "    fsp.young_people,\n",
    "    (num_schools::FLOAT / NULLIF(fsp.young_people, 0)) * 1000 AS schools_per_1000,\n",
    "    (sp.num_schools::FLOAT / NULLIF(sp.area_sq_km, 0)) AS schools_per_sq_km,\n",
    "    0.5 * ((sp.num_schools::FLOAT / NULLIF(fsp.young_people, 0)) * 1000 + (sp.num_schools::FLOAT / NULLIF(sp.area_sq_km, 0))) AS composite_metric\n",
    "FROM\n",
    "    schools_per_sa2 sp\n",
    "JOIN\n",
    "    filtered_sydney_young_people fsp ON sp.sa2_code = fsp.sa2_code;\n",
    "'''\n",
    "\n",
    "zscore_schools = '''\n",
    "CREATE OR REPLACE VIEW zscore_schools AS\n",
    "SELECT\n",
    "    sa2_code,\n",
    "    num_schools,\n",
    "    young_people,\n",
    "    schools_per_1000,\n",
    "    schools_per_sq_km,\n",
    "    composite_metric,\n",
    "    (composite_metric - AVG(composite_metric) OVER ()) / NULLIF(STDDEV(composite_metric) OVER (), 0) AS zscore_schools\n",
    "FROM\n",
    "    schools_per_1000;\n",
    "'''\n",
    "conn.execute(text(join_population_for_young_people))\n",
    "conn.execute(text(schools_per_sa2_view))\n",
    "conn.execute(text(schools_per_1000))\n",
    "conn.execute(text(zscore_schools))\n",
    "conn.commit()\n",
    "\n",
    "query_funct(conn, \"select * from zscore_schools\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comprehensive Analysis of Resource Distribution in SA2 Regions\n",
    "\n",
    "\"well-resourced\" each Statistical Area Level 2 (SA2) in Greater Sydney is. Utilizing a combination of data on businesses, public transport stops, polling places, and schools, we developed a scoring system that integrates these various metrics to provide a holistic view of resource availability across different neighborhoods.\n",
    "\n",
    "\n",
    "### Data\n",
    "\n",
    "- **Business Data**: Extracted from the Australian Bureau of Statistics for the industry 'Professional, Scientific and Technical Services'.\n",
    "- **Transport Stops**: Gathered from Transport for NSW, focusing on the number of public transport stops.\n",
    "- **Polling Places**: Based on locations from the 2019 Federal election, representing civic resources.\n",
    "- **Schools**: Derived from the NSW Department of Education, focusing on the distribution of primary and secondary educational institutions.\n",
    "\n",
    "### Processing / Analysis\n",
    "\n",
    "- **Normalisation**: Each dataset was processed to calculate the metric of resources per 1000 people. This normalization allows for fair comparison across regions with varying population sizes.\n",
    "- **Z-Score Calculation**:\n",
    "  - For each metric, we calculated the mean and standard deviation.\n",
    "  - Z-scores were then computed to standardize the differences across metrics.\n",
    "- **Sigmoid Function Application**:\n",
    "  - Combined the z-scores of all metrics for each region.\n",
    "  - Applied the sigmoid function to these combined scores to map the results to a 0-1 scale, making it easier to interpret and compare.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bustling_scores_view = '''\n",
    "CREATE OR REPLACE VIEW bustling_scores_view AS\n",
    "SELECT\n",
    "    zb.sa2_code,\n",
    "    zb.sa2_name,\n",
    "    zb.zscore_business,\n",
    "    zs.zscore_schools,\n",
    "    zp.zscore_polls,\n",
    "    zst.zscore_stops,\n",
    "    (1 / (1 + EXP(-(zb.zscore_business + zs.zscore_schools + zp.zscore_polls + zst.zscore_stops)))) AS score,\n",
    "    zb.the_geom\n",
    "FROM\n",
    "    zscore_selected_industry_businesses zb\n",
    "LEFT JOIN\n",
    "    zscore_schools zs ON zb.sa2_code = zs.sa2_code\n",
    "LEFT JOIN\n",
    "    zscore_polls zp ON zb.sa2_code = zp.sa2_code\n",
    "LEFT JOIN\n",
    "    zscore_stops zst ON zb.sa2_code = zst.sa2_code21;\n",
    "'''\n",
    "conn.execute(text(bustling_scores_view))\n",
    "conn.commit()\n",
    "\n",
    "query_funct(conn, \"select * from bustling_scores_view\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation for currently bustling scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = '''\n",
    "SELECT sa2_code, sa2_name, zscore_business, zscore_schools, zscore_polls, zscore_stops, score, the_geom\n",
    "FROM bustling_scores_view;\n",
    "'''\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "df_bustling = pd.read_sql(sql, conn)\n",
    "df_bustling.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "sns.histplot(df_bustling['score'], bins=20, kde=True, color='black')\n",
    "plt.title('Distribution of Current Scores')\n",
    "plt.xlabel('Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data into a GeoDataFrame\n",
    "current_bustling_map = gpd.GeoDataFrame.from_postgis(sql, conn, geom_col='the_geom', crs='EPSG:4326')\n",
    "\n",
    "current_bustling_map_projected = current_bustling_map.to_crs(epsg=3857)\n",
    "current_bustling_map_projected['centroid'] = current_bustling_map_projected.geometry.centroid\n",
    "current_bustling_map['centroid'] = current_bustling_map_projected['centroid'].to_crs(epsg=4326)\n",
    "\n",
    "center_lat = current_bustling_map['centroid'].y.mean()\n",
    "center_lon = current_bustling_map['centroid'].x.mean()\n",
    "\n",
    "current_bustling_fig = px.choropleth_mapbox(current_bustling_map, \n",
    "                           geojson=current_bustling_map.geometry.__geo_interface__, \n",
    "                           locations=current_bustling_map.index, \n",
    "                           color='score',\n",
    "                           color_continuous_scale=\"Viridis\",\n",
    "                           range_color=(min(current_bustling_map['score']), max(current_bustling_map['score'])),\n",
    "                           mapbox_style=\"carto-positron\",\n",
    "                           zoom=10, center={\"lat\": center_lat, \"lon\": center_lon},\n",
    "                           opacity=0.5,\n",
    "                           labels={'score':'Score'},\n",
    "                           hover_data=['sa2_name', 'zscore_business', 'zscore_schools', 'zscore_polls', 'zscore_stops'])\n",
    "\n",
    "current_bustling_fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n",
    "\n",
    "current_bustling_fig.show()\n",
    "\n",
    "# current_bustling_fig.write_html('current_bustling_map.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Own Data Set For Steven"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sources: https://data.gov.au/dataset/ds-ga-d9f88f7b-2bec-476b-b907-ef01109f8b3a/details?q=hospitals\n",
    "facilities_spatial = gpd.read_file(\"data/Foundation_Facility_Points.gpkg\")\n",
    "\n",
    "facilities_spatial = facilities_spatial.rename(columns={\"geometry\": \"the_geom\"})\n",
    "\n",
    "columns_to_keep = [\n",
    "    \"OBJECTID\", \"FEATURESUBTYPE\", \"NAME\", \"MAIN_FUNCTION\",\n",
    "    \"OPERATIONALSTATUS\", \"ADDRESS\", \"SUBURB\", \"STATE\", \"CATEGORY\", \"the_geom\"\n",
    "]\n",
    "facilities_clean_gdf = facilities_spatial[columns_to_keep]\n",
    "\n",
    "# Standardize column names\n",
    "facilities_clean_gdf.columns = [\n",
    "    \"facility_id\", \"feature_subtype\", \"name\", \"main_function\",\n",
    "    \"operational_status\", \"address\", \"suburb\", \"state\", \"category\", \"the_geom\"\n",
    "]\n",
    "\n",
    "facilities_clean_gdf.columns = facilities_clean_gdf.columns.str.lower()\n",
    "\n",
    "# Exclude Educational Buildings (120003)\n",
    "educational_subtypes = [120003]\n",
    "facilities_clean_gdf = facilities_clean_gdf[ ~ (facilities_clean_gdf[\"feature_subtype\"].isin(educational_subtypes))]\n",
    "\n",
    "# Filter by state (only New South Wales facilities)\n",
    "facilities_clean_gdf = facilities_clean_gdf[facilities_clean_gdf[\"state\"].isin([\"NSW\", \"nsw\"])]\n",
    "\n",
    "# Remove duplicates\n",
    "facilities_clean_gdf = facilities_clean_gdf.drop_duplicates(subset=\"facility_id\")\n",
    "\n",
    "facilities_clean_gdf = facilities_clean_gdf[facilities_clean_gdf[\"the_geom\"].notna()]\n",
    "facilities_clean_gdf = facilities_clean_gdf[facilities_clean_gdf[\"the_geom\"].is_valid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert geometry to WKT format\n",
    "facilities_clean_gdf['the_geom'] = facilities_clean_gdf['the_geom'].apply(lambda x: create_wkt_element(x, 4326))\n",
    "\n",
    "facilities_clean_gdf.to_sql(\n",
    "    \"all_facilities_clean\",\n",
    "    conn,\n",
    "    if_exists='replace',\n",
    "    index=False,\n",
    "    dtype={'the_geom': Geometry('POINT', 4326)}\n",
    ")\n",
    "\n",
    "# Create a spatial index\n",
    "conn.execute(text(\"CREATE INDEX idx_facility_geom_clean ON all_facilities_clean USING GIST (the_geom);\"))\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facilities_per_sa2_query = '''\n",
    "CREATE OR REPLACE VIEW facilities_per_sa2 AS\n",
    "SELECT\n",
    "    fsp.sa2_code,\n",
    "    sa2.sa2_name21 AS sa2_name,\n",
    "    COALESCE(COUNT(af.facility_id), 0) AS num_facilities,\n",
    "    ST_Area(ST_Transform(sa2.the_geom, 3857)) / POWER(1000, 2) AS area_sq_km \n",
    "FROM\n",
    "    filtered_sydney_population fsp\n",
    "JOIN\n",
    "    sa2_greater_sydney sa2 ON fsp.sa2_code = sa2.sa2_code21\n",
    "LEFT JOIN\n",
    "    all_facilities_clean af ON ST_Contains(sa2.the_geom, af.the_geom)\n",
    "GROUP BY\n",
    "    fsp.sa2_code,\n",
    "    sa2.sa2_name21,\n",
    "    sa2.the_geom;\n",
    "'''\n",
    "\n",
    "adjusted_facility_rate = '''\n",
    "CREATE OR REPLACE VIEW adjusted_facility_rate AS\n",
    "SELECT\n",
    "    sa2_code,\n",
    "    sa2_name,\n",
    "    num_facilities,\n",
    "    num_facilities / NULLIF(area_sq_km, 0) AS facilities_per_sq_km\n",
    "FROM\n",
    "    facilities_per_sa2;\n",
    "'''\n",
    "\n",
    "facility_stats_query = '''\n",
    "CREATE OR REPLACE VIEW facility_stats AS\n",
    "SELECT\n",
    "    AVG(facilities_per_sq_km) AS mean_facilities_per_sq_km,\n",
    "    STDDEV(facilities_per_sq_km) AS stddev_facilities_per_sq_km\n",
    "FROM\n",
    "    adjusted_facility_rate;\n",
    "'''\n",
    "\n",
    "facilities_z_score_query = '''\n",
    "CREATE OR REPLACE VIEW zscore_facilities AS\n",
    "SELECT\n",
    "    afr.sa2_code,\n",
    "    afr.sa2_name,\n",
    "    afr.num_facilities,\n",
    "    afr.facilities_per_sq_km,\n",
    "    (afr.facilities_per_sq_km - fs.mean_facilities_per_sq_km) / fs.stddev_facilities_per_sq_km AS z_score_facilities\n",
    "FROM\n",
    "    adjusted_facility_rate afr,\n",
    "    facility_stats fs;\n",
    "'''\n",
    "\n",
    "# Execute SQL Queries\n",
    "queries = [facilities_per_sa2_query, adjusted_facility_rate, facility_stats_query, facilities_z_score_query]\n",
    "\n",
    "for query in queries:\n",
    "    conn.execute(text(query))\n",
    "    conn.commit()\n",
    "\n",
    "query_funct(conn, \"select * from facilities_per_sa2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Own Data Set For Ryan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "health_facilities = gpd.read_file(\"data/Health_Facilities/hotosm_aus_health_facilities_points_shp.shp\")\n",
    "\n",
    "# Drop columns with many missing values or irrelevant data\n",
    "columns_to_drop = ['name_en', 'building', 'healthca_1', 'operator_t', 'capacity_p', \n",
    "                   'addr_full', 'addr_city', 'source']\n",
    "health_facilities_clean = health_facilities.drop(columns=columns_to_drop)\n",
    "\n",
    "columns_rename = {\n",
    "    'name': 'facility_name',\n",
    "    'amenity': 'facility_type',\n",
    "    'healthcare': 'healthcare_service',\n",
    "    'osm_id': 'openstreetmap_id',\n",
    "    'osm_type': 'openstreetmap_type',\n",
    "    'geometry': 'the_geom'  # Renaming and adjusting case in one step\n",
    "}\n",
    "health_facilities_clean = health_facilities_clean.rename(columns=columns_rename)\n",
    "\n",
    "# Ensure all column names are lowercase\n",
    "health_facilities_clean.columns = health_facilities_clean.columns.str.lower()\n",
    "\n",
    "# Check duplicates considering multiple fields\n",
    "duplicates = health_facilities_clean.duplicated(subset=['facility_name', 'facility_type', 'the_geom'], keep=False)\n",
    "print(f\"Found {duplicates.sum()} potential duplicates.\")\n",
    "\n",
    "health_facilities_clean = health_facilities_clean.drop_duplicates(subset=['facility_name', 'facility_type', 'the_geom'])\n",
    "\n",
    "# Fill missing values in the 'facility_type' column with 'unknown'\n",
    "health_facilities_clean['facility_type'] = health_facilities_clean['facility_type'].fillna('unknown')\n",
    "health_facilities_clean['facility_name'] = health_facilities_clean['facility_name'].fillna('unknown')\n",
    "health_facilities_clean['healthcare_service'] = health_facilities_clean['healthcare_service'].fillna('unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "health_facilities_clean = health_facilities_clean[health_facilities_clean[\"the_geom\"].notna()]\n",
    "health_facilities_clean = health_facilities_clean[health_facilities_clean[\"the_geom\"].is_valid]\n",
    "\n",
    "# Convert geometry to WKT format\n",
    "health_facilities_clean['the_geom'] = health_facilities_clean['the_geom'].apply(lambda x: create_wkt_element(x, 4326))\n",
    "\n",
    "health_facilities_clean.to_sql(\n",
    "    \"healthcare_facilities\",\n",
    "    conn,\n",
    "    if_exists='replace',\n",
    "    index=False,\n",
    "    dtype={'the_geom': Geometry('POINT', 4326)}\n",
    ")\n",
    "\n",
    "spatial_index_health_facilities = '''\n",
    "CREATE INDEX idx_healthcare_facilities_geom\n",
    "ON healthcare_facilities\n",
    "USING GIST (the_geom);\n",
    "'''\n",
    "\n",
    "# Create a spatial index\n",
    "conn.execute(text(spatial_index_health_facilities))\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_healthcare_facilities = '''\n",
    "CREATE OR REPLACE VIEW weighted_healthcare_facilities AS\n",
    "SELECT\n",
    "    h.the_geom,\n",
    "    CASE\n",
    "        WHEN h.facility_type = 'hospital' THEN 4\n",
    "        WHEN h.facility_type = 'clinic' THEN 3\n",
    "        WHEN h.facility_type = 'pharmacy' THEN 2\n",
    "        ELSE 1\n",
    "    END as weight\n",
    "FROM\n",
    "    healthcare_facilities h;\n",
    "'''\n",
    "\n",
    "conn.execute(text(weighted_healthcare_facilities))\n",
    "conn.commit()\n",
    "\n",
    "health_facilities_per_sa2 = '''\n",
    "CREATE OR REPLACE VIEW health_facilities_per_sa2 AS\n",
    "SELECT\n",
    "    fsp.sa2_code,\n",
    "    COALESCE(SUM(whf.weight), 0) AS total_weighted_score,\n",
    "    ST_Area(ST_Transform(sa2.the_geom, 3857)) / POWER(1000, 2) AS area_sq_km \n",
    "FROM\n",
    "    filtered_sydney_population fsp\n",
    "JOIN\n",
    "    sa2_greater_sydney sa2 ON fsp.sa2_code = sa2.sa2_code21\n",
    "LEFT JOIN\n",
    "    weighted_healthcare_facilities whf ON ST_Contains(sa2.the_geom, whf.the_geom)\n",
    "GROUP BY\n",
    "    fsp.sa2_code,\n",
    "    sa2.the_geom;\n",
    "'''\n",
    "\n",
    "conn.execute(text(health_facilities_per_sa2))\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "health_service_status = '''\n",
    "CREATE OR REPLACE VIEW health_service_status AS\n",
    "SELECT\n",
    "    AVG(total_weighted_score / NULLIF(area_sq_km, 0)) AS mean_facilities_per_sq_km,\n",
    "    STDDEV(total_weighted_score / NULLIF(area_sq_km, 0)) AS stddev_facilities_per_sq_km\n",
    "FROM\n",
    "    health_facilities_per_sa2;\n",
    "'''\n",
    "\n",
    "conn.execute(text(health_service_status))\n",
    "conn.commit()\n",
    "\n",
    "zscore_health_service = '''\n",
    "CREATE OR REPLACE VIEW zscore_health_service AS\n",
    "SELECT\n",
    "    f.sa2_code,\n",
    "    f.total_weighted_score / NULLIF(f.area_sq_km, 0) AS facilities_per_sq_km,\n",
    "    (f.total_weighted_score / NULLIF(f.area_sq_km, 0) - fs.mean_facilities_per_sq_km) / fs.stddev_facilities_per_sq_km AS z_score_health\n",
    "FROM\n",
    "    health_facilities_per_sa2 f,\n",
    "    health_service_status fs;\n",
    "'''\n",
    "\n",
    "conn.execute(text(zscore_health_service))\n",
    "conn.commit()\n",
    "\n",
    "query_funct(conn, \"select * from zscore_health_service\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Own Data Set for Rajat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "education_facilities = gpd.read_file(\"data/education_facilities.geojson\")\n",
    "\n",
    "columns_to_drop = ['name:en', 'capacity:persons', 'addr:full', 'source']\n",
    "cleaned_education_facilities = education_facilities.drop(columns=columns_to_drop)\n",
    "\n",
    "columns_rename = {\n",
    "    'name': 'facility_name',\n",
    "    'amenity': 'facility_type',\n",
    "    'building': 'building_type',\n",
    "    'operator:type': 'operator_type',\n",
    "    'osm_id': 'oepnstreemap_id',\n",
    "    'osm_type': 'openstreetmap_type',\n",
    "    'geometry': 'the_geom'  # Renaming and adjusting case in one step\n",
    "}\n",
    "cleaned_education_facilities = cleaned_education_facilities.rename(columns=columns_rename)\n",
    "\n",
    "# Ensure all column names are lowercase\n",
    "cleaned_education_facilities.columns = cleaned_education_facilities.columns.str.lower()\n",
    "\n",
    "# Check duplicates considering multiple fields\n",
    "duplicates = cleaned_education_facilities.duplicated(subset=['facility_name',\n",
    "                                                             'facility_type',\n",
    "                                                             'the_geom'], keep=False\n",
    "                                                    )\n",
    "print(f\"Found {duplicates.sum()} potential duplicates.\")\n",
    "\n",
    "cleaned_education_facilities = cleaned_education_facilities.drop_duplicates(subset=['facility_name',\n",
    "                                                                                    'facility_type',\n",
    "                                                                                    'the_geom']\n",
    "                                                                           )\n",
    "\n",
    "cleaned_education_facilities['facility_name'] = cleaned_education_facilities['facility_name'].fillna('unknown')\n",
    "cleaned_education_facilities['facility_type'] = cleaned_education_facilities['facility_type'].fillna('unknown')\n",
    "cleaned_education_facilities['building_type'] = cleaned_education_facilities['building_type'].fillna('unknown')\n",
    "cleaned_education_facilities['operator_type'] = cleaned_education_facilities['operator_type'].fillna('unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_education_facilities = cleaned_education_facilities[cleaned_education_facilities[\"the_geom\"].notna()]\n",
    "cleaned_education_facilities = cleaned_education_facilities[cleaned_education_facilities[\"the_geom\"].is_valid]\n",
    "\n",
    "# Convert geometry to WKT format\n",
    "cleaned_education_facilities['the_geom'] = cleaned_education_facilities['the_geom'].apply(lambda x: create_wkt_element(x, 4326))\n",
    "\n",
    "\n",
    "cleaned_education_facilities.to_sql(\n",
    "    \"education_facilities\",\n",
    "    conn,\n",
    "    if_exists='replace',\n",
    "    index=False,\n",
    "    dtype={'the_geom': Geometry('MULTIPOLYGON', 4326)}\n",
    ")\n",
    "\n",
    "spatial_index_education_facilities = '''\n",
    "CREATE INDEX idx_education_facilities_geom\n",
    "ON education_facilities\n",
    "USING GIST (the_geom);\n",
    "'''\n",
    "\n",
    "# Create a spatial index\n",
    "conn.execute(text(spatial_index_education_facilities))\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_education_facilities = '''\n",
    "CREATE OR REPLACE VIEW weighted_education_facilities AS\n",
    "SELECT\n",
    "    ef.the_geom,\n",
    "    CASE\n",
    "        WHEN ef.facility_type IN ('school', 'kindergarten') THEN 0\n",
    "        WHEN ef.facility_type IN ('university', 'college', 'research_institute') THEN 4\n",
    "        WHEN ef.facility_type IN ('library', 'childcare', 'community_centre') THEN 2\n",
    "        WHEN ef.facility_type IN ('music_school', 'arts_centre') THEN 3\n",
    "        ELSE 1\n",
    "    END as weight\n",
    "FROM\n",
    "    education_facilities ef;\n",
    "'''\n",
    "\n",
    "conn.execute(text(weighted_education_facilities))\n",
    "\n",
    "education_facilities_per_sa2 = '''\n",
    "CREATE OR REPLACE VIEW education_facilities_per_sa2 AS\n",
    "SELECT\n",
    "    fsp.sa2_code,\n",
    "    COALESCE(SUM(wef.weight), 0) AS total_weighted_score,\n",
    "    ST_Area(ST_Transform(sa2.the_geom, 3857)) / POWER(1000, 2) AS area_sq_km\n",
    "FROM\n",
    "    filtered_sydney_population fsp\n",
    "JOIN\n",
    "    sa2_greater_sydney sa2 ON fsp.sa2_code = sa2.sa2_code21\n",
    "LEFT JOIN\n",
    "    weighted_education_facilities wef ON ST_Contains(sa2.the_geom, wef.the_geom)\n",
    "GROUP BY\n",
    "    fsp.sa2_code,\n",
    "    sa2.the_geom;\n",
    "'''\n",
    "\n",
    "conn.execute(text(education_facilities_per_sa2))\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "education_service_status = '''\n",
    "CREATE OR REPLACE VIEW education_service_status AS\n",
    "SELECT\n",
    "    AVG(total_weighted_score / NULLIF(area_sq_km, 0)) AS mean_facilities_per_sq_km,\n",
    "    STDDEV(total_weighted_score / NULLIF(area_sq_km, 0)) AS stddev_facilities_per_sq_km\n",
    "FROM\n",
    "    education_facilities_per_sa2;\n",
    "'''\n",
    "\n",
    "conn.execute(text(education_service_status))\n",
    "\n",
    "zscore_education_service = '''\n",
    "CREATE OR REPLACE VIEW zscore_education_service AS\n",
    "SELECT\n",
    "    ef.sa2_code,\n",
    "    ef.total_weighted_score / NULLIF(ef.area_sq_km, 0) AS facilities_per_sq_km,\n",
    "    (ef.total_weighted_score / NULLIF(ef.area_sq_km, 0) - ess.mean_facilities_per_sq_km) / ess.stddev_facilities_per_sq_km AS z_score_education\n",
    "FROM\n",
    "    education_facilities_per_sa2 ef,\n",
    "    education_service_status ess;\n",
    "'''\n",
    "\n",
    "conn.execute(text(zscore_education_service))\n",
    "conn.commit()\n",
    "\n",
    "query_funct(conn, \"select * from zscore_education_service\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_bustling_scores_view = '''\n",
    "CREATE OR REPLACE VIEW final_bustling_scores AS\n",
    "SELECT\n",
    "    zb.sa2_code,\n",
    "    zb.sa2_name,\n",
    "    zb.zscore_business,\n",
    "    zs.zscore_schools,\n",
    "    zp.zscore_polls,\n",
    "    zst.zscore_stops,\n",
    "    zf.z_score_facilities,\n",
    "    zhs.z_score_health,\n",
    "    zse.z_score_education,\n",
    "    (1 / (1 + EXP(-(zb.zscore_business + zs.zscore_schools + zp.zscore_polls + zst.zscore_stops + zf.z_score_facilities + zhs.z_score_health + zse.z_score_education)))) AS score,\n",
    "    zb.the_geom\n",
    "FROM\n",
    "    zscore_selected_industry_businesses zb\n",
    "LEFT JOIN\n",
    "    zscore_schools zs ON zb.sa2_code = zs.sa2_code\n",
    "LEFT JOIN\n",
    "    zscore_polls zp ON zb.sa2_code = zp.sa2_code\n",
    "LEFT JOIN\n",
    "    zscore_stops zst ON zb.sa2_code = zst.sa2_code21\n",
    "LEFT JOIN\n",
    "    zscore_facilities zf ON zb.sa2_code = zf.sa2_code\n",
    "LEFT JOIN\n",
    "    zscore_health_service zhs ON zb.sa2_code = zhs.sa2_code\n",
    "LEFT JOIN\n",
    "    zscore_education_service zse ON zb.sa2_code = zse.sa2_code;\n",
    "'''\n",
    "conn.execute(text(final_bustling_scores_view))\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = '''\n",
    "SELECT sa2_code, sa2_name, zscore_business, zscore_schools, zscore_polls, zscore_stops, z_score_facilities, z_score_health, z_score_education, score, the_geom\n",
    "FROM final_bustling_scores;\n",
    "'''\n",
    "\n",
    "final_df_bustling = query_funct(conn, sql)\n",
    "final_df_bustling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visulization For Final Bustling Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "final_df_bustling.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "sns.histplot(final_df_bustling['score'], bins=20, kde=True, color='black')\n",
    "plt.title('Distribution of Final Scores')\n",
    "plt.xlabel('Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load data into a GeoDataFrame\n",
    "final_bustling_map = gpd.GeoDataFrame.from_postgis(sql, conn, geom_col='the_geom', crs='EPSG:4326')\n",
    "\n",
    "final_bustling_map_projected = final_bustling_map.to_crs(epsg=3857)\n",
    "final_bustling_map_projected['centroid'] = final_bustling_map_projected.geometry.centroid\n",
    "final_bustling_map['centroid'] = final_bustling_map_projected['centroid'].to_crs(epsg=4326)\n",
    "\n",
    "center_lat = final_bustling_map['centroid'].y.mean()\n",
    "center_lon = final_bustling_map['centroid'].x.mean()\n",
    "\n",
    "final_bustling_fig = px.choropleth_mapbox(final_bustling_map, \n",
    "                           geojson=final_bustling_map.geometry.__geo_interface__, \n",
    "                           locations=final_bustling_map.index, \n",
    "                           color='score',\n",
    "                           color_continuous_scale=\"Viridis\",\n",
    "                           range_color=(min(final_bustling_map['score']), max(final_bustling_map['score'])),\n",
    "                           mapbox_style=\"carto-positron\",\n",
    "                           zoom=10, center={\"lat\": center_lat, \"lon\": center_lon},\n",
    "                           opacity=0.5,\n",
    "                           labels={'score':'Score'},\n",
    "                           hover_data=['sa2_name', 'zscore_business', 'zscore_schools', 'zscore_polls', 'zscore_stops', 'z_score_facilities', 'z_score_health', 'z_score_education'])\n",
    "\n",
    "final_bustling_fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n",
    "\n",
    "final_bustling_fig.show()\n",
    "\n",
    "# final_bustling_fig.write_html('final_bustling_map.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_get_income_score = '''\n",
    "SELECT\n",
    "    fbs.sa2_code,\n",
    "    si.sa2_name,\n",
    "    fbs.score,\n",
    "    si.median_income\n",
    "FROM\n",
    "    final_bustling_scores AS fbs\n",
    "JOIN\n",
    "    sydney_income AS si\n",
    "ON\n",
    "    fbs.sa2_code = si.sa2_code21;\n",
    "'''\n",
    "\n",
    "result = query_funct(conn, text(sql_get_income_score))\n",
    "\n",
    "correlation = result['score'].corr(result['median_income'])\n",
    "print(\"Correlation Coefficient:\", correlation)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x='score', y='median_income', data=result)\n",
    "plt.title('Scatter Plot of Bustling Score vs Median Income')\n",
    "plt.xlabel('Bustling Score')\n",
    "plt.ylabel('Median Income')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
